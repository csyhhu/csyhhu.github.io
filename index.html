---
layout: default
title: Home
---

<h1> Welcome to my homepage ! </h1>


<img style="height:240px", src="/images/avator.jpg"/>


<p>My name is <b>Chen Shangyu</b>, I am currently a fourth year Ph.D student in School of Computer Science and Engineering, Nanyang Technological University, Singapore. Under supervision of <a href="http://www.ntu.edu.sg/home/sinnopan/">Prof. Sinno Jialin Pan</a>.</p>

<!--
<p>Here is my <a href="/data/CV.pdf">CV</a></p>

<p>Sometimes I will post some articles here. Feel free to read them in <a href="/articles">Articles list</a>.</p>

<p>You can find more about me in <a href="/about">About</a>. </p>-->

<h2>News:</h2>
<li> I am honor to join ByteDance AI Lab, NLP Group in Singapore and work with <a href=https://hangli-hl.com/index.html/>Dr.Li Hang</a> for internship from June - Nov, 2020. </li>
<li> I haven started an Awesome projection: <a href=https://github.com/csyhhu/Awesome-Deep-Neural-Network-Compression/>Awesome Deep Neural Network Compression</a>. Feel free to check it! </li>

<h2>Publications:</h2>
<ul>

<li> Jianda Chen, <b>Shangyu Chen</b> and Sinno Jialin Pan. <a href=https://csyhhu.github.io/>Storage Efficient and Dynamic Flexible Runtime Channel Pruning via Deep Reinforcement Learning</a> To be appear in 34rd Conference on Neural Information Processing Systems 2020 (NeurIPS-20). Virtual. Dec. 6-12, 2020. (Poster)

<li> <b>Shangyu Chen</b>, Wenya Wang and Sinno Jialin Pan. <a href=https://csyhhu.github.io/>MetaQuant: Learning to Quantize by Learning to Penetrate Non-differentiable Quantization</a> Published in Proceedings of the 33rd Conference on Neural Information Processing Systems 2019 (NeurIPS-19). Vancouver, Canada. Dec. 8-14, 2019. (Poster) <a href=https://github.com/csyhhu/MetaQuant>[code]</a><a href=https://papers.nips.cc/paper/8647-metaquant-learning-to-quantize-by-learning-to-penetrate-non-differentiable-quantization>[paper]</a> </li>

<li> <b>Shangyu Chen</b>, Wenya Wang and Sinno Jialin Pan. <a href=https://csyhhu.github.io/>Cooperative Pruning in Cross-Domain Deep Neural Network Compression</a> Published in Proceedings of the 28th International Joint Conference on Artificial Intelligence (IJCAI-19). Macao, China. (Oral) <a href=https://github.com/csyhhu/Co-Prune>[code]</a><a href=/data/Co-Prune.pdf>[paper]</a> </li>

<li> <b>Shangyu Chen</b>, Wenya Wang and Sinno Jialin Pan. <a href=https://csyhhu.github.io/>Deep Neural Network Quantization via Layer-Wise Optimization using Limited Training Data</a> Published Proceedings of the 33rd AAAI Conference on Artificial Intelligence (AAAI-19). Hawaii, USA. Jan. 27 - Feb. 1, 2019. (Oral) <a href=https://github.com/csyhhu/L-DNQ>[code]</a> <a href=/data/L-DNQ.pdf>[paper]</a> </li>

<li> Xin Dong, <b>Shangyu Chen</b> and Sinno Jialin Pan. <a href=https://arxiv.org/abs/1705.07565>Learning to Prune Deep Neural Networks via Layer-wise Optimal Brain Surgeon</a> Published in Proceedings of 31st Neural Information Processing Systems 2017 (NIPS-17). Long Beach, USA. Dec. 4-9, 2017 (Poster). <a href=https://github.com/csyhhu/L-OBS>[code]</a> <a href=https://papers.nips.cc/paper/7071-learning-to-prune-deep-neural-networks-via-layer-wise-optimal-brain-surgeon>[paper]</a> </li>

</ul>